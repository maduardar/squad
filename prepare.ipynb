{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import json, os, argparse\n",
    "import string\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py\n",
    "import urllib.request as urllib\n",
    "from keras.utils.data_utils import get_file\n",
    "from os import path\n",
    "\n",
    "def get_glove_file_path():\n",
    "    SERVER = 'http://nlp.stanford.edu/data/'\n",
    "    VERSION = 'glove.840B.300d'\n",
    "\n",
    "    origin = '{server}{version}.zip'.format(server=SERVER, version=VERSION)\n",
    "    cache_dir = path.join(path.abspath(path.dirname(__file__)), 'data')\n",
    "\n",
    "    fname = '/tmp/glove.zip'\n",
    "    get_file(fname,\n",
    "             origin=origin,\n",
    "             cache_dir=cache_dir,\n",
    "             cache_subdir='',\n",
    "             extract=True)\n",
    "\n",
    "    # Remove unnecessary .zip file and keep only extracted .txt version\n",
    "    os.remove(fname)\n",
    "    return path.join(cache_dir, VERSION) + '.txt'\n",
    "glove_file_path = 'Data/glove.840B.300d.txt'\n",
    "if not path.exists(glove_file_path):\n",
    "    glove_file_path = get_glove_file_path()\n",
    "    \n",
    "\n",
    "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'\n",
    "urllib.urlretrieve(url+'train-v1.1.json', './Data/train-v1.1.json')\n",
    "urllib.urlretrieve(url+'dev-v1.1.json', './Data/dev-v1.1.json')\n",
    "\n",
    "with open('./Data/train-v1.1.json') as json_data:\n",
    "    d = json.load(json_data)\n",
    "with open('./Data/dev-v1.1.json') as json_data:\n",
    "    d1 = json.load(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data upload completed successfully!\n",
      "Start preporation...\n"
     ]
    }
   ],
   "source": [
    "print('Data upload completed successfully!')\n",
    "print('Start preporation...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae077a6366b4406cac252939dad01162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emb_size, emb_dim = 2195876, 300\n",
    "f = open(glove_file_path)\n",
    "word_dict, ind_dict = {}, {}\n",
    "embedding_matrix = np.zeros((emb_size, emb_dim))\n",
    "i = 1\n",
    "for lines in tqdm(f):\n",
    "    conv_err = 0\n",
    "    line = lines.split()\n",
    "    word = line[0]\n",
    "    try:\n",
    "        f = float(line[1])\n",
    "    except:\n",
    "        conv_err += 1\n",
    "    else:\n",
    "        if word not in word_dict and i < emb_size:\n",
    "            vec = np.array(line[1:], dtype='float32')\n",
    "            if vec.shape[0] != emb_dim:\n",
    "                continue\n",
    "            word_dict[word] = i\n",
    "            ind_dict[i] = word\n",
    "            embedding_matrix[i] = vec\n",
    "            i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('Prepared data/embeddings.h5', 'w') as hf:\n",
    "        hf.create_dataset('embeddings', data=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(vector):\n",
    "    global i\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "#     tokenizer = RegexpTokenizer('\\w+|\\$[\\d]+|\\S+')\n",
    "#     tokenizer = RegexpTokenizer('\\w+') \n",
    "    tokenizer = RegexpTokenizer('(\\w+([\\'-]\\w+)*)')\n",
    "    tokens = tokenizer.tokenize(vector)\n",
    "    words = []\n",
    "    for w in tokens:\n",
    "        if w[0].isalnum():\n",
    "            word = w[0].lower()\n",
    "            if word in word_dict:\n",
    "                words.append(word_dict[word])\n",
    "    return words\n",
    "\n",
    "def find(mylist, sublist):\n",
    "    h = len(mylist)\n",
    "    n = len(sublist)\n",
    "    skip = {sublist[i]: n - i - 1 for i in range(n - 1)}\n",
    "    i = n - 1\n",
    "    while i < h:\n",
    "        for j in range(n):\n",
    "            if mylist[i - j] != sublist[-j - 1]:\n",
    "                i += skip.get(mylist[i], n)\n",
    "                break\n",
    "        else:\n",
    "            return i - n + 1\n",
    "    return -1\n",
    "\n",
    "def parse_data(dataset):\n",
    "    context_list = []\n",
    "    question_list = []\n",
    "    answer_list = []\n",
    "    answer_begin = []\n",
    "    answer_end = []\n",
    "    error = 0\n",
    "    \n",
    "    for article in tqdm(dataset):\n",
    "        for paragraph in article['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                for ans in qa['answers']:\n",
    "                    # append both context and questions many times for more than one question/answer\n",
    "                    ques = tokenize(qa['question'])\n",
    "                    if len(ques) < 100:\n",
    "                        cont = tokenize(paragraph['context'])\n",
    "                        b, e = ans['answer_start'], ans['answer_start']+len(ans['text'])\n",
    "                        an = tokenize(paragraph['context'][b:e])\n",
    "                        begin = find(cont, an)\n",
    "                        if begin > 0:\n",
    "                            question_list.append(ques)\n",
    "                            context_list.append(cont)\n",
    "                            answer_list.append(an)\n",
    "                            answer_begin.append(begin)\n",
    "                            answer_end.append(begin + len(an))\n",
    "    return context_list, question_list, answer_list, answer_begin, answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab257d5f9aa4ce4888292106a9bf501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "architecturally the school has a catholic character atop the main gold dome is a golden statue of the virgin mary immediately in front of the main building and facing it is a copper statue of christ with arms upraised with the legend venite ad me omnes next to the main building is the basilica of the sacred heart immediately behind the basilica is the grotto a marian place of prayer and reflection it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to saint bernadette in 1858 at the end of the main drive and in a direct line that connects through 3 statues and the gold dome is a simple modern stone statue of mary "
     ]
    }
   ],
   "source": [
    "print('Preparing train dataset...')\n",
    "context_list, question_list, answer_list, answer_begin, answer_end = parse_data(d['data'])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dev dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b6167809ff4866a9161f8a7a3deed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dev_ind_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6b7a049dd064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_context_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_question_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_answer_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_answer_begin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_answer_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdev_context_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_ind_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_ind_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print('Preparing dev dataset...')\n",
    "dev_context_list, dev_question_list, dev_answer_list, dev_answer_begin, dev_answer_end = parse_data(d1['data'])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_maxlen = 300\n",
    "ques_maxlen = 25\n",
    "answer_maxlen = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(lst, maxlen):\n",
    "    array = np.zeros((len(lst), maxlen), dtype=np.int)\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(min(len(lst[i]) - 1, maxlen)):\n",
    "            array[i][j] = lst[i][j]\n",
    "    return array\n",
    "\n",
    "def padding(context, question, answer, begin, end):\n",
    "    context_array = pad_sequence(context, context_maxlen)\n",
    "    question_array = pad_sequence(question, ques_maxlen)\n",
    "    answer_array = pad_sequence(answer, answer_maxlen)\n",
    "    begin_array = np.zeros((len(begin), context_maxlen), dtype=np.int)\n",
    "    end_array = np.zeros((len(end), context_maxlen), dtype=np.int)\n",
    "\n",
    "    for i in range(len(begin)):\n",
    "        begin_array[i][min(begin[i], context_maxlen - 1)] = 1 \n",
    "\n",
    "    for i in range(len(end)):\n",
    "        end_array[i][min(end[i], context_maxlen - 1)] = 1\n",
    "\n",
    "    print('context: ', context_array.shape)\n",
    "    print('question: ', question_array.shape)\n",
    "    print('answer: ', answer_array.shape)\n",
    "    print('answer start: ', begin_array.shape)\n",
    "    print('answer end: ',end_array.shape)\n",
    "    return context_array, question_array, answer_array, begin_array, end_array\n",
    "def save_data(data_type):\n",
    "    print('Shapes of ' + data_type + ' data')\n",
    "    if data_type == 'test':\n",
    "        context_array, question_array, answer_array, begin_array, end_array = \\\n",
    "        padding(context_list, question_list, answer_list, answer_begin, answer_end)\n",
    "    if data_type == 'dev':\n",
    "        context_array, question_array, answer_array,begin_array, end_array = \\\n",
    "        padding(dev_context_list, dev_question_list,\n",
    "                dev_answer_list, dev_answer_begin, dev_answer_end)\n",
    "    dr = 'Prepared data/' + data_type + '_'\n",
    "    with h5py.File(dr + 'context.h5', 'w') as hf:\n",
    "        hf.create_dataset('context', data=context_array)\n",
    "    with h5py.File(dr + 'questions.h5', 'w') as hf:\n",
    "        hf.create_dataset('questions', data=question_array)\n",
    "    with h5py.File(dr + 'answers.h5', 'w') as hf:\n",
    "        hf.create_dataset('answers', data=answer_array)\n",
    "    with h5py.File(dr + 'begin.h5', 'w') as hf:\n",
    "        hf.create_dataset('begin', data=begin_array)\n",
    "    with h5py.File(dr + 'end.h5', 'w') as hf:\n",
    "        hf.create_dataset('end', data=end_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of test data\n",
      "context:  (80949, 300)\n",
      "question:  (80949, 25)\n",
      "answer:  (80949, 30)\n",
      "answer start:  (80949, 300)\n",
      "answer end:  (80949, 300)\n",
      "Shapes of dev data\n",
      "context:  (32243, 300)\n",
      "question:  (32243, 25)\n",
      "answer:  (32243, 30)\n",
      "answer start:  (32243, 300)\n",
      "answer end:  (32243, 300)\n"
     ]
    }
   ],
   "source": [
    "save_data('test')\n",
    "save_data('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dictionaries\n",
    "dr = 'Prepared data/'\n",
    "np.save(dr + 'word2ind.npy', word_dict)\n",
    "np.save(dr + 'ind2word.npy', ind_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
